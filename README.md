# Inference EGTR (Image to Scene Graphs)
> This repo provides code to extract the Scene Graphs (SGs) that are generated by EGTR since the original work does not provide scripts that solely generate SGs on customized images during inference time. Hope the code can help the folks, please cite or star this repo if this helped!

## Installation
> Mainly follow official repo's instructions, but the followings can make the installation more smoothy.
- Pull specified image from docker repo:  **nvcr.io/nvidia/pytorch:21.11-py3**, and create a container based on this image. 
- Enter the container and git clone the official repo.
- Replace official work's **requirements.txt** with mine to avoid outdated torch and CUDA version.
- Follow the official repo's instructions:
	```Shell
	pip install -r requirements.txt
	cd lib/fpn
	sh make.sh
	```

## Setup
> The following setups are for my inference scripts: **infer_egtr_\*.py**

### Dataset
 - Download VG annotations to get the object and relation labels.
 - Download the annotations of [VG (in COCO-format)](https://drive.google.com/file/d/1aGwEu392DiECGdvwaYr-LgqGLmWhn8yD/view?usp=sharing). The annotations serve for the object and relation labels.
 - Unzip it, which you should get 4 json files (**rel.json**, **test.json**, **train.json**, **val.json**), and place them to your `YOUR_DATA_PATH` folder. You will use `YOUR_DATA_PATH` later executing my scripts.

### Pretrained EGTR checkpoints
- Official pretrained EGTR can be downloaded through this [link](https://drive.google.com/file/d/18phcRxbrEI7HqIuM2OLAPuwAF5k3pUC2/view?usp=drive_link).
 - Unzip it and place the folder to `YOUR_ARTIFACT_PATH`, where the folder should include checkpoints folder and **config.json**. You will use this path later executing my scripts.

## Usage
> You might find more parameters to tune based on your needs in the scripts. The scripts will create a json file of triplets and related graph information for a single image.

### Batch images
Inference all the images under a folder.

```bash
python infer_egtr_batch.py \\
	--image_folder YOUR_IMG_FOLDER_PATH \\
	--artifact_path YOUR_ARTIFACT_PATH \\
	--data_path YOUR_DATA_PATH \\
	--output_dir YOUR_OUTPUT_FOLDER_PATH
```

### Single images
Inference a single image. 

```bash
python infer_egtr_single.py \\
    --image_path YOUR_IMG_PATH \\
    --artifact_path YOUR_ARTIFACT_PATH \\
    --data_path YOUR_DATA_PATH \\
    --output_json YOUR_OUTPUT_PATH
```

## Notes
Check out the **/example_output** folder to see an example image with its scene graph json file.

### Hyperparameters trade-off
- **Object Threshold**: decides how much you filter objects.
- **Relation Threshold**: filters weak relations.
- **Top-K**: caps the maximum, but should not be the only filtering criterion.
- **Number of Queries** (not sure if helpful): decides how much queries the model "ask" the image.

## References
Original work: [EGTR: Extracting Graph from Transformer for Scene Graph Generation](https://arxiv.org/pdf/2404.02072)
Original work's repo: https://github.com/naver-ai/egtr